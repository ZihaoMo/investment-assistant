"""Deep Research æ‰§è¡Œæ¨¡å—"""

import json
import re
import os
from typing import Dict, List, Optional
from datetime import datetime

from .openai_client import OpenAIClient
from .storage import Storage
from .retrieval import SearchManager, format_search_results_for_prompt


DEEP_RESEARCH_PROMPT = """## è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½é¡¶çº§æŠ•èµ„æœºæ„çš„é¦–å¸­ç ”ç©¶å‘˜ï¼Œä»¥ä¸¥è°¨çš„é€»è¾‘ã€æ·±å…¥çš„åˆ†æå’Œç‹¬ç«‹çš„åˆ¤æ–­è‘—ç§°ã€‚ä½ çš„ç ”ç©¶æŠ¥å‘Šç›´æ¥å½±å“æ•°åäº¿ç¾å…ƒçš„æŠ•èµ„å†³ç­–ã€‚

## ç ”ç©¶èƒŒæ™¯

**ç ”ç©¶æ ‡çš„:** {stock_name}
**ç ”ç©¶è§¦å‘åŸå› :** {trigger_reason}

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç”¨æˆ·çš„æŠ•èµ„é€»è¾‘ï¼ˆPlaybookï¼‰

### 1.1 æ€»ä½“æŠ•èµ„æ¡†æ¶ï¼ˆPortfolio Playbookï¼‰
{portfolio_playbook}

### 1.2 ä¸ªè‚¡æŠ•èµ„é€»è¾‘ï¼ˆStock Playbookï¼‰
{stock_playbook}

### 1.3 ç”¨æˆ·åå¥½æ¡£æ¡ˆ
{user_preferences}

**é‡è¦ï¼šä½ éœ€è¦æ·±åˆ»ç†è§£ç”¨æˆ·çš„æŠ•èµ„é€»è¾‘å’Œåå¥½ï¼Œæ¯ä¸€ä¸ªåˆ†æéƒ½è¦å›æ‰£åˆ°è¿™ä¸ªé€»è¾‘æ¡†æ¶ä¸Šã€‚ç¡®ä¿ç ”ç©¶ç»“è®ºä¸ç”¨æˆ·çš„æ€»ä½“æŠ•èµ„ä¸»çº¿ä¿æŒä¸€è‡´ï¼Œå¹¶è€ƒè™‘ç”¨æˆ·çš„å†³ç­–é£æ ¼å’Œåå¥½ã€‚**

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šå†å²ç ”ç©¶ä¸Šä¸‹æ–‡

{research_history}

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæœ¬æ¬¡ Environment å˜åŒ–

{environment_changes}

---

## ç¬¬å››éƒ¨åˆ†ï¼šå†å²ä¸Šä¼ èµ„æ–™

ä»¥ä¸‹æ˜¯ç”¨æˆ·åœ¨è¿‡å¾€ç ”ç©¶ä¸­ä¸Šä¼ çš„é‡è¦å‚è€ƒèµ„æ–™ï¼ˆç ”æŠ¥ã€ä¼šè®®çºªè¦ç­‰ï¼‰ï¼Œè¯·åœ¨åˆ†ææ—¶å‚è€ƒè¿™äº›å†å²ä¿¡æ¯ï¼š

{historical_uploads}

---

## ç¬¬äº”éƒ¨åˆ†ï¼šç ”ç©¶è®¡åˆ’

{research_plan}

---

## ç¬¬å…­éƒ¨åˆ†ï¼šè¡¥å……æœç´¢ç»“æœ

{search_results}

---

## ç ”ç©¶ä»»åŠ¡

åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œå®Œæˆä¸€ä»½ã€æœºæ„çº§åˆ«çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šã€‘ï¼Œè¦æ±‚ï¼š
1. åˆ†æå¿…é¡»æœ‰ç†æœ‰æ®ï¼Œå¼•ç”¨å…·ä½“æ•°æ®å’Œäº‹å®
2. æ¯ä¸ªç»“è®ºéƒ½è¦è¯´æ˜æ¨ç†è¿‡ç¨‹
3. æ˜ç¡®åŒºåˆ†"äº‹å®"ã€"æ¨æ–­"å’Œ"å‡è®¾"
4. è¯†åˆ«åˆ†æä¸­çš„ä¸ç¡®å®šæ€§å’Œé£é™©ç‚¹
5. ç»™å‡ºå¯æ“ä½œçš„å»ºè®®

---

## è¾“å‡ºæ ¼å¼ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„ï¼‰

# {stock_name} æ·±åº¦ç ”ç©¶æŠ¥å‘Š

**ç ”ç©¶æ—¥æœŸ:** [ä»Šå¤©æ—¥æœŸ]
**è§¦å‘äº‹ä»¶:** [ç®€è¿°è§¦å‘åŸå› ]
**æ ¸å¿ƒç»“è®º:** [ä¸€å¥è¯æ ¸å¿ƒç»“è®º]

---

## ä¸€ã€Executive Summaryï¼ˆæ‰§è¡Œæ‘˜è¦ï¼‰

ç”¨ 3-5 ä¸ªè¦ç‚¹æ€»ç»“æœ¬æ¬¡ç ”ç©¶çš„æ ¸å¿ƒå‘ç°ï¼š
-
-
-

**æŠ•èµ„å»ºè®®:** [ä¹°å…¥/å¢æŒ/æŒæœ‰/å‡æŒ/å–å‡º]
**ä¿¡å¿ƒæ°´å¹³:** [é«˜/ä¸­/ä½]
**å»ºè®®ä»“ä½è°ƒæ•´:** [å…·ä½“å»ºè®®]

---

## äºŒã€å…³é”®å˜åŒ–æ·±åº¦è§£æ

å¯¹æ¯ä¸ªé‡è¦å˜åŒ–è¿›è¡Œæ·±å…¥åˆ†æï¼š

### 2.1 [å˜åŒ–1åç§°]

**äº‹å®é™ˆè¿°:** [å®¢è§‚æè¿°å‘ç”Ÿäº†ä»€ä¹ˆ]

**æ·±åº¦è§£è¯»:**
- è¿™ä¸ªå˜åŒ–çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸ºä»€ä¹ˆä¼šåœ¨è¿™ä¸ªæ—¶ç‚¹å‘ç”Ÿï¼Ÿ
- å¸‚åœºçš„ååº”æ˜¯ä»€ä¹ˆï¼Ÿååº”æ˜¯å¦åˆç†ï¼Ÿ

**é‡åŒ–å½±å“è¯„ä¼°:**
- å¯¹æ”¶å…¥çš„å½±å“ï¼š[å…·ä½“æ•°å­—æˆ–èŒƒå›´]
- å¯¹åˆ©æ¶¦çš„å½±å“ï¼š[å…·ä½“æ•°å­—æˆ–èŒƒå›´]
- å¯¹ä¼°å€¼çš„å½±å“ï¼š[å…·ä½“åˆ†æ]

**ä¸æŠ•èµ„é€»è¾‘çš„å…³è”:**
- è¿™ä¸ªå˜åŒ–å¦‚ä½•å½±å“æ ¸å¿ƒè®ºç‚¹ï¼Ÿ[å¼ºåŒ–/å‰Šå¼±/æ— å½±å“]
- å…·ä½“å½±å“å“ªä¸ªè®ºç‚¹ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ

### 2.2 [å˜åŒ–2åç§°]
ï¼ˆåŒä¸Šç»“æ„ï¼‰

---

## ä¸‰ã€æŠ•èµ„é€»è¾‘éªŒè¯

é€ä¸€æ£€éªŒç”¨æˆ· Playbook ä¸­çš„æ ¸å¿ƒè®ºç‚¹ï¼š

### 3.1 æ ¸å¿ƒè®ºç‚¹æ£€éªŒ

| è®ºç‚¹ | åŸå§‹çŠ¶æ€ | æœ¬æ¬¡å˜åŒ–åçŠ¶æ€ | å˜åŒ–åŸå›  | ç½®ä¿¡åº¦å˜åŒ– |
|------|----------|----------------|----------|------------|
| [è®ºç‚¹1] | [ä¹‹å‰çš„åˆ¤æ–­] | [ç°åœ¨çš„åˆ¤æ–­] | [åŸå› ] | [â†‘/â†“/â†’] |
| [è®ºç‚¹2] | ... | ... | ... | ... |

### 3.2 éªŒè¯ä¿¡å·æ£€æŸ¥

| éªŒè¯ä¿¡å· | æ˜¯å¦å‡ºç° | å…·ä½“è¡¨ç° | ä¿¡å·å¼ºåº¦ |
|----------|----------|----------|----------|
| [ä¿¡å·1] | [æ˜¯/å¦/éƒ¨åˆ†] | [æè¿°] | [å¼º/ä¸­/å¼±] |

### 3.3 å¤±æ•ˆæ¡ä»¶æ£€æŸ¥

| å¤±æ•ˆæ¡ä»¶ | æ˜¯å¦è§¦å‘ | å½“å‰çŠ¶æ€ | è·ç¦»è§¦å‘çš„è·ç¦» |
|----------|----------|----------|----------------|
| [æ¡ä»¶1] | [æ˜¯/å¦] | [æè¿°] | [è¿‘/ä¸­/è¿œ] |

---

## å››ã€ç«äº‰æ ¼å±€ä¸äº§ä¸šé“¾åˆ†æ

### 4.1 ç«äº‰å¯¹æ‰‹åŠ¨æ€

| ç«äº‰å¯¹æ‰‹ | è¿‘æœŸåŠ¨ä½œ | å¯¹ç ”ç©¶æ ‡çš„çš„å½±å“ | å¨èƒç¨‹åº¦ |
|----------|----------|------------------|----------|
| [å¯¹æ‰‹1] | [åŠ¨ä½œ] | [å½±å“] | [é«˜/ä¸­/ä½] |

### 4.2 äº§ä¸šé“¾ä¼ å¯¼åˆ†æ

- **ä¸Šæ¸¸å˜åŒ–:** [åˆ†æ]
- **ä¸‹æ¸¸å˜åŒ–:** [åˆ†æ]
- **æ›¿ä»£å“å¨èƒ:** [åˆ†æ]

---

## äº”ã€æƒ…æ™¯åˆ†æä¸ä¼°å€¼å½±å“

### 5.1 ä¸‰ç§æƒ…æ™¯

**ä¹è§‚æƒ…æ™¯ (æ¦‚ç‡: X%)**
- å‡è®¾æ¡ä»¶ï¼š
- é¢„æœŸç»“æœï¼š
- ç›®æ ‡ä»·/ä¼°å€¼ï¼š

**åŸºå‡†æƒ…æ™¯ (æ¦‚ç‡: X%)**
- å‡è®¾æ¡ä»¶ï¼š
- é¢„æœŸç»“æœï¼š
- ç›®æ ‡ä»·/ä¼°å€¼ï¼š

**æ‚²è§‚æƒ…æ™¯ (æ¦‚ç‡: X%)**
- å‡è®¾æ¡ä»¶ï¼š
- é¢„æœŸç»“æœï¼š
- ç›®æ ‡ä»·/ä¼°å€¼ï¼š

### 5.2 å…³é”®å˜é‡æ•æ„Ÿæ€§

| å…³é”®å˜é‡ | å½“å‰å‡è®¾ | ä¸Šè¡Œæƒ…æ™¯ | ä¸‹è¡Œæƒ…æ™¯ | å¯¹ä¼°å€¼çš„å½±å“ |
|----------|----------|----------|----------|--------------|
| [å˜é‡1] | [å€¼] | [å€¼] | [å€¼] | [å½±å“] |

---

## å…­ã€é£é™©æç¤º

### 6.1 å·²è¯†åˆ«é£é™©

| é£é™©ç±»å‹ | é£é™©æè¿° | å‘ç”Ÿæ¦‚ç‡ | æ½œåœ¨å½±å“ | åº”å¯¹ç­–ç•¥ |
|----------|----------|----------|----------|----------|
| [ç±»å‹] | [æè¿°] | [é«˜/ä¸­/ä½] | [æè¿°] | [ç­–ç•¥] |

### 6.2 æœªçŸ¥é£é™©ä¸ç›²ç‚¹

- æœ¬æ¬¡åˆ†æå¯èƒ½é—æ¼çš„è§’åº¦ï¼š
- æ•°æ®å±€é™æ€§è¯´æ˜ï¼š
- éœ€è¦è¿›ä¸€æ­¥éªŒè¯çš„å‡è®¾ï¼š

---

## ä¸ƒã€è¡ŒåŠ¨å»ºè®®

### 7.1 ç«‹å³è¡ŒåŠ¨é¡¹

1. [å…·ä½“è¡ŒåŠ¨1]
2. [å…·ä½“è¡ŒåŠ¨2]

### 7.2 æŒç»­è·Ÿè¸ªé¡¹

| è·Ÿè¸ªäº‹é¡¹ | è·Ÿè¸ªé¢‘ç‡ | å…³é”®é˜ˆå€¼ | è§¦å‘è¡ŒåŠ¨ |
|----------|----------|----------|----------|
| [äº‹é¡¹1] | [é¢‘ç‡] | [é˜ˆå€¼] | [è¡ŒåŠ¨] |

### 7.3 ä¸‹æ¬¡ç ”ç©¶è§¦å‘æ¡ä»¶

- å½“å‡ºç°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œéœ€è¦é‡æ–°è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼š
  1. [æ¡ä»¶1]
  2. [æ¡ä»¶2]

---

## å…«ã€ç»“è®º JSON

```json
{{
  "research_date": "[æ—¥æœŸ]",
  "stock": "{stock_name}",
  "thesis_impact": "å¼ºåŒ–/å‰Šå¼±/åŠ¨æ‘‡/æ— å½±å“",
  "recommendation": "ä¹°å…¥/å¢æŒ/æŒæœ‰/å‡æŒ/å–å‡º",
  "confidence": "é«˜/ä¸­/ä½",
  "position_suggestion": "å…·ä½“ä»“ä½å»ºè®®",
  "key_finding": "æœ€é‡è¦çš„å‘ç°ï¼ˆä¸€å¥è¯ï¼‰",
  "reasoning": "æ ¸å¿ƒæ¨ç†é€»è¾‘ï¼ˆ2-3å¥è¯ï¼‰",
  "bull_case_probability": 30,
  "base_case_probability": 50,
  "bear_case_probability": 20,
  "key_risks": ["é£é™©1", "é£é™©2"],
  "key_catalysts": ["å‚¬åŒ–å‰‚1", "å‚¬åŒ–å‰‚2"],
  "follow_up_items": ["è·Ÿè¸ªäº‹é¡¹1", "è·Ÿè¸ªäº‹é¡¹2"],
  "next_research_trigger": ["è§¦å‘æ¡ä»¶1", "è§¦å‘æ¡ä»¶2"]
}}
```

---

## ä¹ã€å…è´£å£°æ˜

æœ¬æŠ¥å‘ŠåŸºäºå…¬å¼€ä¿¡æ¯å’ŒAIåˆ†æç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…ã€‚"""


class ResearchEngine:
    """Deep Research æ‰§è¡Œå¼•æ“"""

    def __init__(self, client: OpenAIClient, storage: Storage):
        self.client = client
        self.storage = storage

    def execute_research(
        self,
        stock_id: str,
        research_plan: Dict,
        environment_data: Dict
    ) -> Dict:
        """æ‰§è¡Œæ·±åº¦ç ”ç©¶"""
        # è·å–ç›¸å…³æ•°æ®
        portfolio_playbook = self.storage.get_portfolio_playbook()
        stock_playbook = self.storage.get_stock_playbook(stock_id)
        recent_history = self.storage.get_recent_research(stock_id, limit=5)

        stock_name = stock_playbook.get("stock_name", stock_id) if stock_playbook else stock_id

        # è·å–ç”¨æˆ·åå¥½
        user_preferences = self.storage.get_preferences_for_prompt()

        # è·å–å†å²ä¸Šä¼ æ–‡ä»¶
        historical_uploads = self.storage.get_historical_uploads(stock_id, limit=5)

        # æ‰§è¡Œæœç´¢
        search_results = self._execute_searches(research_plan, stock_playbook)

        # æ ¼å¼åŒ–æ•°æ®
        portfolio_str = json.dumps(portfolio_playbook, ensure_ascii=False, indent=2) if portfolio_playbook else "ï¼ˆæš‚æ— ï¼‰"
        stock_playbook_str = json.dumps(stock_playbook, ensure_ascii=False, indent=2) if stock_playbook else "ï¼ˆæš‚æ— ï¼‰"

        # è·å–åŒ…å«ç”¨æˆ·åé¦ˆçš„ç ”ç©¶ä¸Šä¸‹æ–‡
        research_context = self.storage.get_research_context(stock_id, limit=3)

        history_str = "ï¼ˆæš‚æ— ï¼‰"
        if research_context:
            history_items = []
            for r in research_context:
                result = r.get("research_result", {})
                feedback = r.get("user_feedback", {})

                item = f"### ç ”ç©¶æ—¥æœŸ: {r.get('date', '')[:10]}\n"
                item += f"**AIå»ºè®®:** {result.get('recommendation', 'æœªçŸ¥')} | **ä¿¡å¿ƒ:** {result.get('confidence', 'æœªçŸ¥')}\n"
                item += f"**æ ¸å¿ƒæ¨ç†:** {result.get('reasoning', 'æ— ')}\n"

                if feedback:
                    item += f"\n**ç”¨æˆ·åé¦ˆ:**\n"
                    item += f"- ç ”ç©¶æ˜¯å¦æœ‰ä»·å€¼: {'æ˜¯' if feedback.get('research_valuable', True) else 'å¦'}\n"
                    item += f"- æ–¹å‘è¯„ä»·: {feedback.get('direction_correct', 'æœªè¯„ä»·')}\n"
                    item += f"- ç”¨æˆ·å†³ç­–: {feedback.get('decision', 'æœªå†³ç­–')}\n"
                    if feedback.get('tracking_metrics'):
                        item += f"- ç”¨æˆ·å…³æ³¨çš„è·Ÿè¸ªæŒ‡æ ‡: {', '.join(feedback.get('tracking_metrics', []))}\n"
                    if feedback.get('notes'):
                        item += f"- ç”¨æˆ·å¤‡æ³¨: {feedback.get('notes')}\n"
                    if feedback.get('next_direction'):
                        item += f"- ç”¨æˆ·å¸Œæœ›çš„åç»­ç ”ç©¶æ–¹å‘: {feedback.get('next_direction')}\n"

                history_items.append(item)

            history_str = "\n---\n".join(history_items)
        elif recent_history:
            # å…œåº•ï¼šå¦‚æœæ²¡æœ‰å¸¦åé¦ˆçš„è®°å½•ï¼Œä½¿ç”¨æ™®é€šå†å²
            history_items = []
            for r in recent_history:
                result = r.get("research_result", {})
                history_items.append(
                    f"- {r.get('date', '')[:10]}: "
                    f"å»ºè®®{result.get('recommendation', '')}ï¼Œ"
                    f"ç†ç”±ï¼š{result.get('reasoning', '')}"
                )
            history_str = "\n".join(history_items)

        env_str = self._format_environment(environment_data)
        plan_str = json.dumps(research_plan, ensure_ascii=False, indent=2)

        # æ ¼å¼åŒ–å†å²ä¸Šä¼ æ–‡ä»¶
        historical_str = "ï¼ˆæš‚æ— å†å²ä¸Šä¼ èµ„æ–™ï¼‰"
        if historical_uploads:
            hist_items = []
            for h in historical_uploads:
                hist_items.append(f"### [{h.get('date', '')}] {h.get('filename', '')}")
                if h.get('summary'):
                    hist_items.append(f"{h.get('summary', '')}")
                hist_items.append("")  # ç©ºè¡Œåˆ†éš”
            historical_str = "\n".join(hist_items)

        # è°ƒç”¨ AI æ‰§è¡Œç ”ç©¶
        prompt = DEEP_RESEARCH_PROMPT.format(
            stock_name=stock_name,
            trigger_reason=research_plan.get("trigger_reason", ""),
            portfolio_playbook=portfolio_str,
            stock_playbook=stock_playbook_str,
            user_preferences=user_preferences,
            research_history=history_str,
            environment_changes=env_str,
            historical_uploads=historical_str,
            research_plan=plan_str,
            search_results=search_results
        )

        response = self.client.chat(prompt)

        # è§£æç»“è®º
        conclusion = self._extract_conclusion(response)

        # æ„å»ºå…³é”®å‘ç°åˆ—è¡¨ï¼ˆç”¨äºå› æœé€»è¾‘å±•ç¤ºï¼‰
        key_findings = []
        if conclusion.get("key_finding"):
            key_findings.append(conclusion.get("key_finding"))
        if conclusion.get("key_catalysts"):
            for catalyst in conclusion.get("key_catalysts", [])[:2]:
                key_findings.append(f"å‚¬åŒ–å‰‚: {catalyst}")
        if conclusion.get("key_risks"):
            for risk in conclusion.get("key_risks", [])[:2]:
                key_findings.append(f"é£é™©: {risk}")

        return {
            "full_report": response,
            "conclusion": conclusion,
            "key_findings": key_findings,
            "search_results": search_results,
            "executed_at": datetime.now().isoformat()
        }

    def _execute_searches(self, research_plan: Dict, playbook: Optional[Dict]) -> str:
        """æ‰§è¡Œç ”ç©¶è®¡åˆ’ä¸­çš„æœç´¢ã€‚

        ç›®æ ‡ï¼šæ›´é€‚é…æœ¬ç¯å¢ƒã€äº§å‡ºå¯æ ¸éªŒè¯æ®ã€‚
        - ä¸èµ°æµè§ˆå™¨ï¼ˆé¿å…éªŒè¯ç ï¼‰
        - é€šè¿‡ OpenClaw Gateway `web_search` tool ä½¿ç”¨ Braveï¼ˆä¸ç›´è¿ Brave HTTP APIï¼‰
        - ä¼˜å…ˆ Tavilyï¼Œå…¶æ¬¡ OpenClaw web_searchï¼ˆunion åˆå¹¶å»é‡ï¼‰
        - è¾“å‡ºåŒ…å« URL + snippetï¼Œä¾¿äºæŠ¥å‘Šå¼•ç”¨
        - ç»“æœå¸¦ç¼“å­˜/é¢„ç®—ï¼Œé™ä½ SIGKILL é£é™©
        """

        # Lazy import to keep startup fast
        from .retrieval import SearchManager, TavilyProvider, OpenClawWebSearchProvider, format_search_results_for_prompt

        sm = SearchManager(
            providers=[
                TavilyProvider() if os.getenv("TAVILY_API_KEY") else None,
                OpenClawWebSearchProvider(),
            ],
            cache_ttl_seconds=12 * 3600,
            hard_timeout_seconds=25,
        )

        results: List[str] = []

        def run_query(q: str) -> str:
            hits = sm.search(q, max_results=5, topic="news", depth="basic")
            return format_search_results_for_prompt(hits, limit=5)

        research_modules = research_plan.get("research_modules", [])
        if research_modules:
            for module in research_modules:
                module_name = module.get("module_name", "æœªå‘½åæ¨¡å—")
                search_queries = module.get("search_queries", [])
                key_questions = module.get("key_questions", [])

                results.append(f"\n## ğŸ“Š ç ”ç©¶æ¨¡å—: {module_name}\n")

                for query in (search_queries or [])[:3]:
                    results.append(f"### ğŸ” æœç´¢: {query}\n{run_query(query)}\n")

                if not search_queries and key_questions:
                    for q in key_questions[:2]:
                        results.append(f"### ğŸ” é—®é¢˜: {q}\n{run_query(q)}\n")

        if not results:
            hypotheses = research_plan.get("hypothesis_to_test", [])
            for h in hypotheses[:2]:
                how_to_verify = (h.get("how_to_verify", "") or "").strip()
                if how_to_verify:
                    results.append(f"### ğŸ” éªŒè¯å‡è®¾: {h.get('hypothesis', '')}\n{run_query(how_to_verify)}\n")

        if not results:
            objective = (research_plan.get("research_objective", "") or "").strip()
            if objective:
                results.append(f"### ğŸ” ç ”ç©¶ç›®æ ‡: {objective}\n{run_query(objective)}\n")

            questions = research_plan.get("core_questions", [])
            for q in questions[:3]:
                results.append(f"### ğŸ” {q}\n{run_query(q)}\n")

        return "\n".join(results) if results else "ï¼ˆæœªæ‰§è¡Œæœç´¢ï¼‰"

    def _format_environment(self, environment_data: Dict) -> str:
        """æ ¼å¼åŒ– Environment æ•°æ®"""
        lines = []

        auto = environment_data.get("auto_collected", [])
        if auto:
            lines.append("è‡ªåŠ¨é‡‡é›†:")
            for item in auto:
                lines.append(f"  - [{item.get('date', '')}] {item.get('title', '')}")

        uploaded = environment_data.get("user_uploaded", [])
        if uploaded:
            lines.append("\nç”¨æˆ·ä¸Šä¼ :")
            for item in uploaded:
                lines.append(f"  - {item.get('filename', '')}: {item.get('summary', '')[:100]}...")

        return "\n".join(lines) if lines else "ï¼ˆæ— å˜åŒ–æ•°æ®ï¼‰"

    def _extract_conclusion(self, response: str) -> Dict:
        """ä»å“åº”ä¸­æå–ç»“è®º JSON"""
        parse_error = None

        # å°è¯•ä» markdown code block ä¸­æå–
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', response)
        if json_match:
            try:
                result = json.loads(json_match.group(1))
                result["_parse_success"] = True
                return result
            except json.JSONDecodeError as e:
                parse_error = f"JSON è§£æé”™è¯¯ (code block): {str(e)}"
                self.storage.log(parse_error, "WARNING")

        # å°è¯•æŸ¥æ‰¾æ›´å®Œæ•´çš„ JSON å¯¹è±¡ï¼ˆåŒ…å«åµŒå¥—ï¼‰
        # ä» "research_date" æˆ– "thesis_impact" å¼€å§‹æŸ¥æ‰¾
        json_pattern = r'\{[^{}]*(?:"research_date"|"thesis_impact")[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        match = re.search(json_pattern, response)
        if match:
            try:
                result = json.loads(match.group(0))
                result["_parse_success"] = True
                return result
            except json.JSONDecodeError as e:
                parse_error = f"JSON è§£æé”™è¯¯ (pattern match): {str(e)}"
                self.storage.log(parse_error, "WARNING")

        # è¿”å›é»˜è®¤ç»“æ„ï¼Œæ ‡è®°è§£æå¤±è´¥
        self.storage.log(f"ç»“è®º JSON è§£æå¤±è´¥: {parse_error}", "ERROR")
        return {
            "thesis_impact": "å¾…å®š",
            "recommendation": "å¾…å®š",
            "confidence": "ä½",
            "reasoning": "æ— æ³•è‡ªåŠ¨è§£æç»“è®ºï¼Œè¯·æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š",
            "follow_up_items": [],
            "_parse_success": False,
            "_parse_error": parse_error or "æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON ç»“æ„"
        }

    def save_research_record(
        self,
        stock_id: str,
        environment_data: Dict,
        impact_assessment: Dict,
        research_result: Optional[Dict],
        user_feedback: Optional[Dict] = None
    ):
        """ä¿å­˜ç ”ç©¶è®°å½•"""
        record = {
            "trigger": "user_initiated",
            "environment_input": {
                "time_range": environment_data.get("time_range", "7d"),
                "auto_collected": environment_data.get("auto_collected", []),
                "user_uploaded": environment_data.get("user_uploaded", [])
            },
            "impact_assessment": {
                "needs_deep_research": impact_assessment.get("judgment", {}).get("needs_deep_research", False),
                "reason": impact_assessment.get("conclusion", {}).get("reason", ""),
                "affected_thesis_points": impact_assessment.get("research_plan", {}).get("related_playbook_points", [])
            },
            "research_plan": impact_assessment.get("research_plan"),
            "research_result": research_result.get("conclusion") if research_result else None,
            "full_report": research_result.get("full_report") if research_result else None,
            "user_feedback": user_feedback
        }

        self.storage.add_research_record(stock_id, record)

    def collect_feedback(self, recommendation: str) -> Dict:
        """æ”¶é›†ç”¨æˆ·åé¦ˆï¼ˆè¿”å›ç»“æ„ï¼Œç”±ä¸»ç¨‹åºå¡«å……ï¼‰"""
        return {
            "final_decision": None,
            "differs_from_recommendation": False,
            "reason": None,
            "actual_result": None
        }
